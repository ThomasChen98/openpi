# =============================================================================
# H1 Integrated Training Pipeline Configuration
# =============================================================================
# This is the SINGLE SOURCE OF TRUTH for all training pipeline settings.
# Edit this file to configure your training run.
#
# Usage:
#   1. Edit this file with your task and environment settings
#   2. Run: ./scripts/integrated_training.sh
#   3. On robot: python h1_execution_client.py --config training_config.yaml
# =============================================================================

# =============================================================================
# TASK CONFIGURATION - What task are we training?
# =============================================================================
task:
  name: "lift_lid_reward_dec11"                              # Short name for directories/checkpoints
  description: "Lift the lid off the bowl and place it on the table"     # Full description used as prompt
  
# =============================================================================
# POLICY CONFIGURATION - Model and checkpoints
# =============================================================================
policy:
  config_name: "pi05_h1_auto"                   # Policy config (pi05_h1_auto, pi05_h1_finetune, etc.)
  base_checkpoint: "/home/yuxin/Projects/openpi/checkpoints/pi05_h1_auto/pi05_h1_move_lid/999"
  # ^ Pretrained checkpoint for epoch 0. Leave empty to train from scratch.

# =============================================================================
# TRAINING CONFIGURATION - How to train
# =============================================================================
training:
  max_epochs: 1000                               # Maximum training epochs
  save_interval: 1000                            # Save interval (in epochs)
  keep_period: 1000                              # Keep period (in epochs)
  num_repeats: 2                                # Times to repeat data during training
  labeling_mode: "reward_labeling"               # none, human_labeling, reward_labeling
  gpu_id: 0                                     # Which GPU to use

# =============================================================================
# REWARD LABELING CONFIGURATION - For reward_labeling mode
# =============================================================================
reward:
  # Detailed task instruction for the VLM reward model
  # Should include success criteria and failure conditions
  task_instruction: |
    Lift the lid on top of the bowl with both hands, move it steadily away from the bowl, and place it flat on the table.
    The robot must use its two hands to do carefully put the lid on the table.
    Very important: The task fails if the lid slips, flipped, drops, or is knocked off during lifting or placement.
    The task fails if the lid is not placed flat on the table (e.g., still connected to the bowl).
    The task fails if the hands of the robot are colliding with the bowl or the table.
    If the task fails, all the frames after the failure should be scored 0.
  
  max_frames: 30                                # Maximum frames to sample for VLM
  image_rotation: 0                             # Image rotation (0, 90, 180, 270)
  advantage_threshold: 0.3                      # Percentile threshold (0.0-1.0): top 30% = Advantage=True

# =============================================================================
# SERVER CONFIGURATION - Policy server settings
# =============================================================================
policy_server:
  host: "localhost"                             # Server host (use IP if robot connects remotely)
  port: 8000                                    # Server port
  poll_interval_sec: 5                          # How often robot polls for status

# =============================================================================
# ROBOT CONFIGURATION - H1-2 robot settings
# =============================================================================
robot:
  network_interface: "eno1"                     # Network interface for DDS
  left_hand_ip: "192.168.123.211"               # Left Inspire hand IP
  right_hand_ip: "192.168.123.210"              # Right Inspire hand IP
  head_camera_server_ip: "192.168.123.163"      # Robot head camera IP
  head_camera_server_port: 5555                 # Robot head camera port

# =============================================================================
# DATA CONFIGURATION - Where to save/load data
# =============================================================================
data:
  # Local paths (on robot)
  save_dir: "./h1_data_auto"            # Where robot saves episodes
  
  # Remote sync settings (robot -> P6000)
  rsync:
    enabled: true
    target: "P6000:/home/yuxin/Projects/openpi/examples/h1_control_client/h1_data_auto"
    options: "-avz --progress"
    ssh_key: "~/.ssh/id_rsa"

# =============================================================================
# RECORDING CONFIGURATION - Episode recording settings
# =============================================================================
recording:
  fps: 50                                       # Recording frequency (Hz)
  image_quality: 85                             # JPEG compression quality (1-100)

# =============================================================================
# PIPELINE CONFIGURATION - Integrated training settings
# =============================================================================
pipeline:
  start_phase: "data_collection"                # data_collection or training
  start_epoch: 0                                # Starting epoch number
  auto_sync: true                               # Auto-sync after session ends



